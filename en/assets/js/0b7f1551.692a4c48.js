"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[7282],{52881:function(e,o,a){a.r(o),a.d(o,{assets:function(){return i},contentTitle:function(){return d},default:function(){return c},frontMatter:function(){return l},metadata:function(){return s},toc:function(){return u}});var n=a(83117),t=a(80102),r=(a(67294),a(3905)),p=["components"],l={id:"Hadoop\u4ecb\u7ecd\u4e0e\u5b89\u88c5",slug:"/1Hadoop\u4ecb\u7ecd\u4e0e\u5b89\u88c5",title:"1 Hadoop\u4ecb\u7ecd\u4e0e\u5b89\u88c5",author:"RiverMountain",date:"2023/06/13",tags:["\u5927\u6570\u636e","hadoop"],keywords:["\u5927\u6570\u636e","hadoop"],description:"Hadoop\u4ecb\u7ecd\u4e0e\u5b89\u88c5",last_update:{date:"2023/06/13"}},d=void 0,s={unversionedId:"course/\u5927\u6570\u636e/hadoop/Hadoop\u4ecb\u7ecd\u4e0e\u5b89\u88c5",id:"course/\u5927\u6570\u636e/hadoop/Hadoop\u4ecb\u7ecd\u4e0e\u5b89\u88c5",title:"1 Hadoop\u4ecb\u7ecd\u4e0e\u5b89\u88c5",description:"Hadoop\u4ecb\u7ecd\u4e0e\u5b89\u88c5",source:"@site/docs/course/\u5927\u6570\u636e/hadoop/1 Hadoop\u4ecb\u7ecd\u4e0e\u5b89\u88c5.md",sourceDirName:"course/\u5927\u6570\u636e/hadoop",slug:"/1Hadoop\u4ecb\u7ecd\u4e0e\u5b89\u88c5",permalink:"/en/docs/1Hadoop\u4ecb\u7ecd\u4e0e\u5b89\u88c5",draft:!1,tags:[{label:"\u5927\u6570\u636e",permalink:"/en/docs/tags/\u5927\u6570\u636e"},{label:"hadoop",permalink:"/en/docs/tags/hadoop"}],version:"current",frontMatter:{id:"Hadoop\u4ecb\u7ecd\u4e0e\u5b89\u88c5",slug:"/1Hadoop\u4ecb\u7ecd\u4e0e\u5b89\u88c5",title:"1 Hadoop\u4ecb\u7ecd\u4e0e\u5b89\u88c5",author:"RiverMountain",date:"2023/06/13",tags:["\u5927\u6570\u636e","hadoop"],keywords:["\u5927\u6570\u636e","hadoop"],description:"Hadoop\u4ecb\u7ecd\u4e0e\u5b89\u88c5",last_update:{date:"2023/06/13"}},sidebar:"course",previous:{title:"\u5927\u6570\u636e",permalink:"/en/docs/category/\u5927\u6570\u636e"},next:{title:"2 HDFS\u6587\u4ef6\u5b58\u50a8\u539f\u7406",permalink:"/en/docs/2HDFS\u6587\u4ef6\u5b58\u50a8\u539f\u7406"}},i={},u=[{value:"Hadoop\u7b80\u8981\u6982\u8ff0",id:"hadoop\u7b80\u8981\u6982\u8ff0",level:2},{value:"Hadoop HDFS\u914d\u7f6e",id:"hadoop-hdfs\u914d\u7f6e",level:2},{value:"\u6839\u76ee\u5f55\u7ed3\u6784",id:"\u6839\u76ee\u5f55\u7ed3\u6784",level:3},{value:"\u4fee\u6539\u6587\u4ef6",id:"\u4fee\u6539\u6587\u4ef6",level:3},{value:"workers",id:"workers",level:4},{value:"hadoop-env.sh",id:"hadoop-envsh",level:4},{value:"core-site.xml",id:"core-sitexml",level:4},{value:"hdfs-site.xml",id:"hdfs-sitexml",level:4},{value:"\u5206\u53d1",id:"\u5206\u53d1",level:3},{value:"\u6743\u9650\u5206\u914d\u7ed9hadoop\u7528\u6237",id:"\u6743\u9650\u5206\u914d\u7ed9hadoop\u7528\u6237",level:4},{value:"\u542f\u52a8",id:"\u542f\u52a8",level:2},{value:"\u683c\u5f0f\u5316\u6587\u4ef6\u7cfb\u7edf",id:"\u683c\u5f0f\u5316\u6587\u4ef6\u7cfb\u7edf",level:3},{value:"\u542f\u52a8\u7a0b\u5e8f",id:"\u542f\u52a8\u7a0b\u5e8f",level:3},{value:"\u542f\u505c\u7ba1\u7406\u547d\u4ee4",id:"\u542f\u505c\u7ba1\u7406\u547d\u4ee4",level:3},{value:"\u4e00\u952e\u542f\u505c",id:"\u4e00\u952e\u542f\u505c",level:4},{value:"\u5355\u8fdb\u7a0b\u542f\u505c",id:"\u5355\u8fdb\u7a0b\u542f\u505c",level:4},{value:"FS Shell",id:"fs-shell",level:3},{value:"\u7f51\u9875\u67e5\u770b\u6587\u4ef6",id:"\u7f51\u9875\u67e5\u770b\u6587\u4ef6",level:3},{value:"\u914d\u7f6eNFS",id:"\u914d\u7f6enfs",level:2},{value:"\u6dfb\u52a0 core-site.xml \u914d\u7f6e",id:"\u6dfb\u52a0-core-sitexml-\u914d\u7f6e",level:4},{value:"\u6dfb\u52a0 hdfs-site.xml \u914d\u7f6e",id:"\u6dfb\u52a0-hdfs-sitexml-\u914d\u7f6e",level:4},{value:"\u542f\u52a8nfs",id:"\u542f\u52a8nfs",level:4},{value:"\u542f\u52a8\u4e0e\u505c\u6b62\u811a\u672c",id:"\u542f\u52a8\u4e0e\u505c\u6b62\u811a\u672c",level:2},{value:"\u4e00\u952e\u542f\u52a8\u811a\u672c",id:"\u4e00\u952e\u542f\u52a8\u811a\u672c",level:3},{value:"\u4e00\u952e\u5173\u95ed\u811a\u672c",id:"\u4e00\u952e\u5173\u95ed\u811a\u672c",level:3}],h={toc:u},m="wrapper";function c(e){var o=e.components,l=(0,t.Z)(e,p);return(0,r.kt)(m,(0,n.Z)({},h,l,{components:o,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"hadoop\u7b80\u8981\u6982\u8ff0"},"Hadoop\u7b80\u8981\u6982\u8ff0"),(0,r.kt)("p",null,"Hadoop\u662f\u4e00\u4e2a\u7531Apache\u57fa\u91d1\u4f1a\u6240\u5f00\u53d1\u7684",(0,r.kt)("a",{parentName:"p",href:"https://baike.baidu.com/item/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/4905336?fromModule=lemma_inlink"},"\u5206\u5e03\u5f0f\u7cfb\u7edf"),"\u57fa\u7840\u67b6\u6784\u3002\u7528\u6237\u53ef\u4ee5\u5728\u4e0d\u4e86\u89e3\u5206\u5e03\u5f0f\u5e95\u5c42\u7ec6\u8282\u7684\u60c5\u51b5\u4e0b\uff0c\u5f00\u53d1\u5206\u5e03\u5f0f\u7a0b\u5e8f\u3002\u5145\u5206\u5229\u7528\u96c6\u7fa4\u7684\u5a01\u529b\u8fdb\u884c\u9ad8\u901f\u8fd0\u7b97\u548c\u5b58\u50a8\u3002Hadoop\u5b9e\u73b0\u4e86\u4e00\u4e2a",(0,r.kt)("a",{parentName:"p",href:"https://baike.baidu.com/item/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/1250388?fromModule=lemma_inlink"},"\u5206\u5e03\u5f0f\u6587\u4ef6\u7cfb\u7edf"),"\uff08 Distributed File System\uff09\uff0c\u5176\u4e2d\u4e00\u4e2a\u7ec4\u4ef6\u662f",(0,r.kt)("a",{parentName:"p",href:"https://baike.baidu.com/item/HDFS/4836121?fromModule=lemma_inlink"},"HDFS"),"\uff08Hadoop Distributed File System\uff09\u3002HDFS\u6709\u9ad8",(0,r.kt)("a",{parentName:"p",href:"https://baike.baidu.com/item/%E5%AE%B9%E9%94%99%E6%80%A7/9131391?fromModule=lemma_inlink"},"\u5bb9\u9519\u6027"),"\u7684\u7279\u70b9\uff0c\u5e76\u4e14\u8bbe\u8ba1\u7528\u6765\u90e8\u7f72\u5728\u4f4e\u5ec9\u7684\uff08low-cost\uff09\u786c\u4ef6\u4e0a\uff1b\u800c\u4e14\u5b83\u63d0\u4f9b\u9ad8\u541e\u5410\u91cf\uff08high throughput\uff09\u6765\u8bbf\u95ee",(0,r.kt)("a",{parentName:"p",href:"https://baike.baidu.com/item/%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F/5985445?fromModule=lemma_inlink"},"\u5e94\u7528\u7a0b\u5e8f"),"\u7684\u6570\u636e\uff0c\u9002\u5408\u90a3\u4e9b\u6709\u7740\u8d85\u5927\u6570\u636e\u96c6\uff08large data set\uff09\u7684\u5e94\u7528\u7a0b\u5e8f\u3002HDFS\u653e\u5bbd\u4e86\uff08relax\uff09",(0,r.kt)("a",{parentName:"p",href:"https://baike.baidu.com/item/POSIX/3792413?fromModule=lemma_inlink"},"POSIX"),"\u7684\u8981\u6c42\uff0c\u53ef\u4ee5\u4ee5\u6d41\u7684\u5f62\u5f0f\u8bbf\u95ee\uff08streaming access\uff09\u6587\u4ef6\u7cfb\u7edf\u4e2d\u7684\u6570\u636e\u3002Hadoop\u7684\u6846\u67b6\u6700\u6838\u5fc3\u7684\u8bbe\u8ba1\u5c31\u662f\uff1a",(0,r.kt)("a",{parentName:"p",href:"https://baike.baidu.com/item/HDFS/4836121?fromModule=lemma_inlink"},"HDFS"),"\u548c",(0,r.kt)("a",{parentName:"p",href:"https://baike.baidu.com/item/MapReduce/133425?fromModule=lemma_inlink"},"MapReduce"),"\u3002HDFS\u4e3a\u6d77\u91cf\u7684\u6570\u636e\u63d0\u4f9b\u4e86\u5b58\u50a8\uff0c\u800cMapReduce\u5219\u4e3a\u6d77\u91cf\u7684\u6570\u636e\u63d0\u4f9b\u4e86\u8ba1\u7b97\u3002"),(0,r.kt)("h2",{id:"hadoop-hdfs\u914d\u7f6e"},"Hadoop HDFS\u914d\u7f6e"),(0,r.kt)("h3",{id:"\u6839\u76ee\u5f55\u7ed3\u6784"},"\u6839\u76ee\u5f55\u7ed3\u6784"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},".\n\u251c\u2500\u2500 bin   #\u5b58\u653ehadoop\u5404\u7c7b\u7a0b\u5e8f\n\u251c\u2500\u2500 etc   #\u914d\u7f6e\u6587\u4ef6\n\u251c\u2500\u2500 include #\u6e90\u4ee3\u7801\n\u251c\u2500\u2500 lib      #\u52a8\u6001\u94fe\u63a5\u5e93\n\u251c\u2500\u2500 libexec  # \u811a\u672c\n\u251c\u2500\u2500 licenses-binary #\u8bb8\u53ef\u6587\u4ef6\n\u251c\u2500\u2500 sbin  #super bin \u7ba1\u7406\u5458\u7a0b\u5e8f\n\u2514\u2500\u2500 share #\u4e8c\u8fdb\u5236\u4ee3\u7801\uff0cjar\u5305\n8 directories\n")),(0,r.kt)("h3",{id:"\u4fee\u6539\u6587\u4ef6"},"\u4fee\u6539\u6587\u4ef6"),(0,r.kt)("p",null,"\u4fee\u6539/etc/hadoop\u4e0b\u7684\u6587\u4ef6"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"workers \u914d\u7f6e\u4ece\u8282\u70b9\u6709\u54ea\u4e9b"),(0,r.kt)("li",{parentName:"ul"},"hadoop-env.sh \u73af\u5883\u53d8\u91cf"),(0,r.kt)("li",{parentName:"ul"},"core-site.xml hadoop\u6838\u5fc3\u914d\u7f6e\u6587\u4ef6"),(0,r.kt)("li",{parentName:"ul"},"hdfs-site.xml hdfs\u6838\u5fc3\u914d\u7f6e\u6587\u4ef6")),(0,r.kt)("h4",{id:"workers"},"workers"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"[root@node1 hadoop]# cat workers \nnode1\nnode2\nnode3\n")),(0,r.kt)("h4",{id:"hadoop-envsh"},"hadoop-env.sh"),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"\u6dfb\u52a0\u4ee5\u4e0b\u8def\u5f84"),(0,r.kt)("pre",{parentName:"blockquote"},(0,r.kt)("code",{parentName:"pre",className:"language-sh"},"export JAVA_HOME=/export/server/jdk\nexport HADOOP_HOME=/export/server/hadoop\nexport HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop\nexport HADOOP_LOG_DIR=$HADOOP_HOME/logs\n"))),(0,r.kt)("h4",{id:"core-sitexml"},"core-site.xml"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-xml"},"<configuration>\n        <property>\n                <name>fs.defaultFS</name>\n                <value>hdfs://node1:8020</value>\n        </property>\n        <property>\n                <name>io.file.buffer.size</name>\n                <value>131072</value>\n        </property>\n</configuration>\n")),(0,r.kt)("h4",{id:"hdfs-sitexml"},"hdfs-site.xml"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-xml"},"<configuration>\n        <property>\n                <name>dfs.datanode.data.dir.perm</name>\n                <value>700</value>\n        </property>\n        <property>\n                <name>dfs.namenode.name.dir</name>\n                <value>/data/nn</value>\n        </property>\n        <property>\n                <name>dfs.namenode.hosts</name>\n                <value>node1,node2,node3</value>\n        </property>\n        <property>\n                <name>dfs.blocksize</name>\n                <value>268435456</value>\n        </property>\n        <property>\n                <name>dfs.namenode.handler.count</name>\n                <value>100</value>\n        </property>\n        <property>\n                <name>dfs.datanode.data.dir</name>\n                <value>/data/dn</value>\n        </property>\n</configuration>\n")),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"\u540c\u65f6\u4f60\u9700\u8981\u5728node1\u4e0a\u65b0\u5efa\u6587\u4ef6\u5939/data/nn \u4e0e /data/dn\uff0cnode2\uff0cnode3\u5efa\u7acb/data/dn")),(0,r.kt)("h3",{id:"\u5206\u53d1"},"\u5206\u53d1"),(0,r.kt)("p",null,"\u901a\u8fc7\u8fdc\u7a0bssh\u5206\u53d1hadoop\u8f6f\u4ef6\u5230node2\u3001node3"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"scp -r hadoop node2:`pwd`/\nscp -r hadoop node3:`pwd`/\n")),(0,r.kt)("p",null,"\u5728node2\u4e0enode3\u6267\u884c\u8f6f\u94fe\u63a5"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"ln -s /export/server/hadoop-3.3.5 ./hadoop\n")),(0,r.kt)("p",null,"\u914d\u7f6e\u73af\u5883\u53d8\u91cf"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"export HADOOP_HOME=/export/server/hadoop\nexport PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin\n")),(0,r.kt)("h4",{id:"\u6743\u9650\u5206\u914d\u7ed9hadoop\u7528\u6237"},"\u6743\u9650\u5206\u914d\u7ed9hadoop\u7528\u6237"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"[root@node1 server]# chown -R hadoop:hadoop /data\n[root@node1 server]# chown -R hadoop:hadoop /export\n[root@node1 server]# ll\n\u603b\u7528\u91cf 8\nlrwxrwxrwx  1 hadoop hadoop   28  6\u6708 13 12:36 hadoop -> /export/server/hadoop-3.3.5/\ndrwxr-xr-x 10 hadoop hadoop 4096  3\u6708 16 00:58 hadoop-3.3.5\nlrwxrwxrwx  1 hadoop hadoop   28  6\u6708 13 12:07 jdk -> /export/server/jdk1.8.0_371/\ndrwxr-xr-x  8 hadoop hadoop 4096  6\u6708 13 12:06 jdk1.8.0_371\n[root@node1 server]# cd /data\n[root@node1 data]# ll\n\u603b\u7528\u91cf 0\ndrwxr-xr-x 2 hadoop hadoop 6  6\u6708 13 13:24 dn\ndrwxr-xr-x 2 hadoop hadoop 6  6\u6708 13 13:24 nn\n[root@node1 data]# \n")),(0,r.kt)("h2",{id:"\u542f\u52a8"},"\u542f\u52a8"),(0,r.kt)("h3",{id:"\u683c\u5f0f\u5316\u6587\u4ef6\u7cfb\u7edf"},"\u683c\u5f0f\u5316\u6587\u4ef6\u7cfb\u7edf"),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"\u786e\u4fdd\u5728hadoop\u7528\u6237\u4e0b\u6267\u884c")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'[root@node1 ~]# su - hadoop\n[hadoop@node1 ~]$ hadoop namenode -format\nWARNING: Use of this script to execute namenode is deprecated.\nWARNING: Attempting to execute replacement "hdfs namenode" instead.\n\nWARNING: /export/server/hadoop/logs does not exist. Creating.\n...\n')),(0,r.kt)("p",null,"\u683c\u5f0f\u5316\u540e\u4f1a\u5728\u6587\u4ef6\u5939/data/nn\u51fa\u73b0\u4ee5\u4e0b\u5185\u5bb9"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"drwx------ 2 hadoop hadoop 112  6\u6708 13 13:43 current\n[hadoop@node1 nn]$ cd current/\n[hadoop@node1 current]$ ll\n\u603b\u7528\u91cf 16\n-rw-r--r-- 1 hadoop hadoop 401  6\u6708 13 13:43 fsimage_0000000000000000000\n-rw-r--r-- 1 hadoop hadoop  62  6\u6708 13 13:43 fsimage_0000000000000000000.md5\n-rw-r--r-- 1 hadoop hadoop   2  6\u6708 13 13:43 seen_txid\n-rw-r--r-- 1 hadoop hadoop 217  6\u6708 13 13:43 VERSION\n[hadoop@node1 current]$ \n")),(0,r.kt)("h3",{id:"\u542f\u52a8\u7a0b\u5e8f"},"\u542f\u52a8\u7a0b\u5e8f"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"[hadoop@node1 ~]$ start-dfs.sh\nStarting namenodes on [node1]\nStarting datanodes\nnode2: WARNING: /export/server/hadoop/logs does not exist. Creating.\nnode3: WARNING: /export/server/hadoop/logs does not exist. Creating.\nStarting secondary namenodes [node1]\n# \u540e\u53f0java\u8fd0\u884c\u7a0b\u5e8f\n[hadoop@node1 ~]$ jps\n11969 SecondaryNameNode\n12263 Jps\n11388 NameNode\n11580 DataNode\n")),(0,r.kt)("h3",{id:"\u542f\u505c\u7ba1\u7406\u547d\u4ee4"},"\u542f\u505c\u7ba1\u7406\u547d\u4ee4"),(0,r.kt)("h4",{id:"\u4e00\u952e\u542f\u505c"},"\u4e00\u952e\u542f\u505c"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"start-dfs.sh \u4e00\u952e\u542f\u52a8HDFS\u96c6\u7fa4"),(0,r.kt)("li",{parentName:"ul"},"stop-dfs.sh \u4e00\u952e\u5173\u95ed\u96c6\u7fa4")),(0,r.kt)("h4",{id:"\u5355\u8fdb\u7a0b\u542f\u505c"},"\u5355\u8fdb\u7a0b\u542f\u505c"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"hadoop-daemon.sh (start | status | stop) (namenode | secondarynamenode | datanode)"),(0,r.kt)("li",{parentName:"ul"},"hdfs --daemon (start | status | stop) (namenode | secondarynamenode | datanode)")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'[hadoop@node1 ~]$ hadoop-daemon.sh stop datanode\nWARNING: Use of this script to stop HDFS daemons is deprecated.\nWARNING: Attempting to execute replacement "hdfs --daemon stop" instead.\n[hadoop@node1 ~]$ hdfs --daemon stop secondarynamenode\n[hadoop@node1 ~]$ jps\n15318 Jps\n11388 NameNode\n[hadoop@node1 ~]$ hdfs --daemon start secondarynamenode\n[hadoop@node1 ~]$ hdfs --daemon start datanode\n[hadoop@node1 ~]$ jps\n15713 Jps\n15604 DataNode\n15479 SecondaryNameNode\n11388 NameNode\n[hadoop@node1 ~]$ \n')),(0,r.kt)("h3",{id:"fs-shell"},"FS Shell"),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"\u53c2\u8003 ",(0,r.kt)("a",{parentName:"p",href:"https://hadoop.apache.org/docs/r3.3.5/hadoop-project-dist/hadoop-common/FileSystemShell.html"},"Apache Hadoop 3.3.5 \u2013 FileSystemShell"))),(0,r.kt)("p",null,"\u4e24\u6761\u91cd\u8981\u524d\u7f00\uff1a"),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"hdfs: Hadoop Distributed File System"),(0,r.kt)("pre",{parentName:"blockquote"},(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"hadoop fs <args>\nhdfs dfs <args>\n")),(0,r.kt)("ul",{parentName:"blockquote"},(0,r.kt)("li",{parentName:"ul"},"\u521b\u5efa\u6587\u4ef6\u5939 \uff1a ",(0,r.kt)("inlineCode",{parentName:"li"},"hadoop fs/hdfs dfs -mkdir -p <psth>")),(0,r.kt)("li",{parentName:"ul"},"\u67e5\u770b\u76ee\u5f55\u4e0b\u6587\u4ef6\uff1a  ",(0,r.kt)("inlineCode",{parentName:"li"},"hadoop fs/hdfs dfs -ls [-h] [-R] <psth>")),(0,r.kt)("li",{parentName:"ul"},"\u4e0a\u4f20\u6587\u4ef6\u5230HDFS\u6307\u5b9a\u76ee\u5f55")),(0,r.kt)("pre",{parentName:"blockquote"},(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"hadoop fs -put [-f] [-p] <localsrc> ... <dst>\nhdfs dfs -put [-f] [-p] <localsrc> ... <dst>\n# -p \u8986\u76d6\u76ee\u6807\u6587\u4ef6\n# -p \u4fdd\u7559\u6587\u4ef6\u5c5e\u6027\n")),(0,r.kt)("ul",{parentName:"blockquote"},(0,r.kt)("li",{parentName:"ul"},"\u67e5\u770b\u6587\u4ef6cat \uff1a",(0,r.kt)("inlineCode",{parentName:"li"},"hadoop fs/hdfs dfs -cat <psth> | more")),(0,r.kt)("li",{parentName:"ul"},"\u4e0b\u8f7d\u6587\u4ef6\uff1a  ",(0,r.kt)("inlineCode",{parentName:"li"},"hadoop fs/hdfs dfs -get [-f] [-p] <src> ... <localdst>")),(0,r.kt)("li",{parentName:"ul"},"\u8ffd\u52a0\u6570\u636e\u5230\u6587\u4ef6\u4e2d\uff1a ",(0,r.kt)("inlineCode",{parentName:"li"},"hadoop fs/hdfs dfs -appendToFile <localsrc> ... <dst>")),(0,r.kt)("li",{parentName:"ul"},"\u5220\u9664\u6587\u4ef6\uff1a ",(0,r.kt)("inlineCode",{parentName:"li"},"hadoop fs/hdfs dfs -rm -r [-skipTrash] URL [URL ...]")))),(0,r.kt)("p",null,"\u542f\u7528\u56de\u6536\u7ad9\u529f\u80fd(core-site.xml)"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"<property>\n    <name>fs.trash.interval</name>\n     <value>1440</value> %%\u4fdd\u7559\u4e00\u5929%%\n</property>\n<property>\n    <name>fs.trash.checkpoint.interval</name>\n    <value>120</value>\n</property>\n")),(0,r.kt)("p",null,"\u56de\u6536\u7ed3\u679c\uff1a"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"[hadoop@node1 ~]$ hadoop fs -rm -r /home\n2023-06-13 14:53:15,100 INFO fs.TrashPolicyDefault: Moved: 'hdfs://node1:8020/home' to trash at: hdfs://node1:8020/user/hadoop/.Trash/Current/home\n\n[hadoop@node1 ~]$ hadoop fs -ls -R /\ndrwx------   - hadoop supergroup          0 2023-06-13 14:53 /user\ndrwx------   - hadoop supergroup          0 2023-06-13 14:53 /user/hadoop\ndrwx------   - hadoop supergroup          0 2023-06-13 14:53 /user/hadoop/.Trash\ndrwx------   - hadoop supergroup          0 2023-06-13 14:53 /user/hadoop/.Trash/Current\ndrwxr-xr-x   - hadoop supergroup          0 2023-06-13 14:23 /user/hadoop/.Trash/Current/home\ndrwxr-xr-x   - hadoop supergroup          0 2023-06-13 14:23 /user/hadoop/.Trash/Current/home/hadoop\n")),(0,r.kt)("h3",{id:"\u7f51\u9875\u67e5\u770b\u6587\u4ef6"},"\u7f51\u9875\u67e5\u770b\u6587\u4ef6"),(0,r.kt)("p",null,"\u7f51\u7ad9\u7aef\u53e3\uff1a",(0,r.kt)("inlineCode",{parentName:"p"},"localhost:9870")),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"\u7f51\u9875\u67e5\u770b\u6587\u4ef6",src:a(95001).Z,width:"1567",height:"824"})),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"\u8fd9\u91cc\u95ee\u4ec0\u4e48\u4f1a\u51fa\u73b0  ",(0,r.kt)("inlineCode",{parentName:"p"},"Permission denied: user=dr.who")," \u56e0\u4e3a\u6211\u4eec\u5728\u6d4f\u89c8\u7f51\u9875\u7684\u65f6\u5019\u76f8\u5f53\u4e8e\u662f\u533f\u540d\u7528\u6237\uff0c\u6ca1\u6709\u6743\u9650\u3002")),(0,r.kt)("p",null,"\u4e5f\u53ef\u5728\u914d\u7f6e\u6587\u4ef6\u4fee\u6539\u6743\u9650(core-site.xml)\uff0c\u9700\u8981\u91cd\u542f\u96c6\u7fa4\uff1a"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-xml"},"<property>\n    <name>hadoop.http.staticuser.user</name>\n    <value>hadoop</value>\n</property>\n")),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"\u4e0d\u63a8\u8350\u53ef\u4ee5\u7ed9\u7f51\u9875\u6d4f\u89c8\u52a0\u4ee5\u9ad8\u6743\u9650\uff0c\u6709\u5f88\u5927\u7684\u5b89\u5168\u95ee\u9898\uff0c\u9020\u6210\u6570\u636e\u7684\u6cc4\u9732\u4e0e\u4e22\u5931")),(0,r.kt)("h2",{id:"\u914d\u7f6enfs"},"\u914d\u7f6eNFS"),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"network files system")),(0,r.kt)("h4",{id:"\u6dfb\u52a0-core-sitexml-\u914d\u7f6e"},"\u6dfb\u52a0 core-site.xml \u914d\u7f6e"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-xml"},"<property>\n    <name>hadoop.proxyuser.hadoop.groups</name>\n    <value>*</value>\n</property>\n<property>\n    <name>hadoop.proxyuser.hadoop.hosts</name>\n    <value>*</value>\n</property>\n")),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"proxyuser.hadoop.groups \u5141\u8bb8\u4ee3\u7406\u4efb\u4f55\u7528\u6237\u7ec4\nproxyuser.hadoop.hosts \u5141\u8bb8\u4ee3\u7406\u4efb\u610f\u670d\u52a1\u5668\u8bf7\u6c42")),(0,r.kt)("h4",{id:"\u6dfb\u52a0-hdfs-sitexml-\u914d\u7f6e"},"\u6dfb\u52a0 hdfs-site.xml \u914d\u7f6e"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-xml"},"<property>\n    <name>nfs.superuser</name>\n    <value>hadoop</value>\n</property>\n<property>\n    <name>nfs.dump.dir</name>\n    <value>/temp/.hdfs-nfs</value>\n</property>\n<property>\n    <name>nfs.exports.allowed.hosts</name>\n    <value>192.168.3.1 rw</value>\n</property>\n")),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"proxyuser.hadoop.groups \u5141\u8bb8\u4ee3\u7406\u4efb\u4f55\u7528\u6237\u7ec4\nproxyuser.hadoop.hosts \u5141\u8bb8\u4ee3\u7406\u4efb\u610f\u670d\u52a1\u5668\u8bf7\u6c42")),(0,r.kt)("h4",{id:"\u542f\u52a8nfs"},"\u542f\u52a8nfs"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"\u5206\u53d1\u4ee5\u4e0a\u914d\u7f6e\u597d\u7684\u6587\u4ef6"),(0,r.kt)("li",{parentName:"ol"},"\u91cd\u542f\u96c6\u7fa4"),(0,r.kt)("li",{parentName:"ol"},"\u505c\u6b62\u7cfb\u7edf\u539f\u5148\u81ea\u5e26\u7684nfs\u76f8\u5173\u8fdb\u7a0b\uff0c\u540c\u65f6\u5378\u8f7d\u6389\u81ea\u5e26\u7684",(0,r.kt)("inlineCode",{parentName:"li"},"rpcbind"),(0,r.kt)("blockquote",{parentName:"li"},(0,r.kt)("p",{parentName:"blockquote"},"yum remove -y rpcbind"))),(0,r.kt)("li",{parentName:"ol"},"\u542f\u52a8portmap\uff1a",(0,r.kt)("inlineCode",{parentName:"li"},"hdfs --daemon start portmap")," (",(0,r.kt)("strong",{parentName:"li"},"\u8981\u5728root\u4e0b\u6267\u884c"),")"),(0,r.kt)("li",{parentName:"ol"},"\u542f\u52a8nfs\uff1a",(0,r.kt)("inlineCode",{parentName:"li"},"hdfs --daemon start nfs3"),"\uff08",(0,r.kt)("strong",{parentName:"li"},"\u5728hadoop\u4e0b\u6267\u884c"),"\uff09",(0,r.kt)("blockquote",{parentName:"li"},(0,r.kt)("p",{parentName:"blockquote"},"windows\u6302\u8f7dnfs: net use X: ","\\","192.168.3.133","!")))),(0,r.kt)("h2",{id:"\u542f\u52a8\u4e0e\u505c\u6b62\u811a\u672c"},"\u542f\u52a8\u4e0e\u505c\u6b62\u811a\u672c"),(0,r.kt)("h3",{id:"\u4e00\u952e\u542f\u52a8\u811a\u672c"},"\u4e00\u952e\u542f\u52a8\u811a\u672c"),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"\u8bf7\u6839\u636e\u9700\u6c42\u4fee\u6539\uff1a",(0,r.kt)("inlineCode",{parentName:"p"},"software"),",",(0,r.kt)("inlineCode",{parentName:"p"},"hadoop"),",",(0,r.kt)("inlineCode",{parentName:"p"},"spark"),"\u7684\u53ef\u6267\u884c\u8def\u5f84")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'#!/bin/bash\nsoftware="/export/server"\nhadoop="$software/hadoop"\nspark="$software/spark"\nlog_file="$software/logs/startlogs/$(date +%Y-%m-%d_%H-%M-%S).log"\n\nif jps | grep -q "NameNode"; then\n    echo "Hadoop\u5df2\u7ecf\u5728\u8fd0\u884c"\nelse\n    echo "\u6b63\u5728\u542f\u52a8\u4f60\u7684\u96c6\u7fa4,\u9ed8\u8ba4\u8f6f\u4ef6\u8def\u5f84\u4e3a$software --"\n    sleep 1s\n    echo "\u6b63\u5728\u542f\u52a8hadoop------------------------"\n    start-dfs.sh 2>&1 | tee -a $log_file\nfi\n\nif jps | grep -q "ResourceManager"; then\n    echo "Yarn\u5df2\u7ecf\u5728\u8fd0\u884c"\nelse\n    echo "\u6b63\u5728\u542f\u52a8yarn--------------------------"\n    start-yarn.sh 2>&1 | tee -a $log_file\nfi\n\nif jps | grep -q "JobHistoryServer"; then\n    echo "\u5386\u53f2\u670d\u52a1\u5668\u5df2\u7ecf\u5728\u8fd0\u884c"\nelse\n    echo "\u542f\u52a8hadoop\u4e0eyarn\u6210\u529f,\u6b63\u5728\u542f\u52a8\u5386\u53f2\u670d\u52a1\u5668---"\n    mapred --daemon start historyserver 2>&1 | tee -a $log_file\nfi\n\nif jps | grep -q "Master"; then\n    echo "Spark\u5df2\u7ecf\u5728\u8fd0\u884c"\nelse\n    echo "\u6b63\u5728\u542f\u52a8spark-------------------------"\n    sleep 1s\n    $spark/sbin/start-history-server.sh 2>&1 | tee -a $log_file\n    $spark/sbin/start-all.sh 2>&1 | tee -a $log_file\nfi\necho "\u96c6\u7fa4\u5168\u90e8\u5df2\u7ecf\u542f\u52a8\u6210\u529f\uff01"\n')),(0,r.kt)("h3",{id:"\u4e00\u952e\u5173\u95ed\u811a\u672c"},"\u4e00\u952e\u5173\u95ed\u811a\u672c"),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"\u8bf7\u6839\u636e\u9700\u6c42\u4fee\u6539\uff1a",(0,r.kt)("inlineCode",{parentName:"p"},"software"),",",(0,r.kt)("inlineCode",{parentName:"p"},"hadoop"),",",(0,r.kt)("inlineCode",{parentName:"p"},"spark"),"\u7684\u53ef\u6267\u884c\u8def\u5f84")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'#!/bin/bash\n\n# Set the log file name\nsoftware="/export/server"\nhadoop="$software/hadoop"\nspark="$software/spark"\nlog_file="$software/logs/stoplogs/$(date +%Y-%m-%d_%H-%M-%S).log"\n\n# Stop Spark and save the output to the log file and print to the console\nif jps | grep -q "Master"; then\n    $spark/sbin/stop-all.sh 2>&1 | tee -a $log_file\n    $spark/sbin/stop-history-server.sh 2>&1 | tee -a $log_file\nelse\n    echo "Spark\u5df2\u7ecf\u505c\u6b62"\nfi\n\n# Stop MapReduce history server and save the output to the log file and print to the console\nif jps | grep -q "JobHistoryServer"; then\n    mapred --daemon stop historyserver 2>&1 | tee -a $log_file\nelse\n    echo "\u5386\u53f2\u670d\u52a1\u5668\u5df2\u7ecf\u505c\u6b62"\nfi\n\n# Stop YARN and save the output to the log file and print to the console\nif jps | grep -q "ResourceManager"; then\n    stop-yarn.sh 2>&1 | tee -a $log_file\nelse\n    echo "Yarn\u5df2\u7ecf\u505c\u6b62"\nfi\n\n# Stop HDFS and save the output to the log file and print to the console\nif jps | grep -q "NameNode"; then\n    stop-dfs.sh 2>&1 | tee -a $log_file\nelse\n    echo "Hadoop\u5df2\u7ecf\u505c\u6b62"\nfi\n')))}c.isMDXComponent=!0},3905:function(e,o,a){a.d(o,{Zo:function(){return i},kt:function(){return c}});var n=a(67294);function t(e,o,a){return o in e?Object.defineProperty(e,o,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[o]=a,e}function r(e,o){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);o&&(n=n.filter((function(o){return Object.getOwnPropertyDescriptor(e,o).enumerable}))),a.push.apply(a,n)}return a}function p(e){for(var o=1;o<arguments.length;o++){var a=null!=arguments[o]?arguments[o]:{};o%2?r(Object(a),!0).forEach((function(o){t(e,o,a[o])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(o){Object.defineProperty(e,o,Object.getOwnPropertyDescriptor(a,o))}))}return e}function l(e,o){if(null==e)return{};var a,n,t=function(e,o){if(null==e)return{};var a,n,t={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],o.indexOf(a)>=0||(t[a]=e[a]);return t}(e,o);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],o.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(t[a]=e[a])}return t}var d=n.createContext({}),s=function(e){var o=n.useContext(d),a=o;return e&&(a="function"==typeof e?e(o):p(p({},o),e)),a},i=function(e){var o=s(e.components);return n.createElement(d.Provider,{value:o},e.children)},u="mdxType",h={inlineCode:"code",wrapper:function(e){var o=e.children;return n.createElement(n.Fragment,{},o)}},m=n.forwardRef((function(e,o){var a=e.components,t=e.mdxType,r=e.originalType,d=e.parentName,i=l(e,["components","mdxType","originalType","parentName"]),u=s(a),m=t,c=u["".concat(d,".").concat(m)]||u[m]||h[m]||r;return a?n.createElement(c,p(p({ref:o},i),{},{components:a})):n.createElement(c,p({ref:o},i))}));function c(e,o){var a=arguments,t=o&&o.mdxType;if("string"==typeof e||t){var r=a.length,p=new Array(r);p[0]=m;var l={};for(var d in o)hasOwnProperty.call(o,d)&&(l[d]=o[d]);l.originalType=e,l[u]="string"==typeof e?e:t,p[1]=l;for(var s=2;s<r;s++)p[s]=a[s];return n.createElement.apply(null,p)}return n.createElement.apply(null,a)}m.displayName="MDXCreateElement"},95001:function(e,o,a){o.Z=a.p+"assets/images/image-20230613150109-7b04ead79fcc05f3e83468dd8aa409ba.png"}}]);